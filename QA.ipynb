{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\d103771\\Documents\\GitHub\\SAR3\\.venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import os\n",
    "from functools import reduce\n",
    "\n",
    "class SemanticDocument():\n",
    "    def __init__(self, QA_folder_path, passages_folder_path, model_name = 'airnicco8/xlm-roberta-en-it-de'):\n",
    "        documents = {'Q':{}, 'p':{}}\n",
    "        embedded_documents = {'Q':{}, 'p':{}}\n",
    "        model = SentenceTransformer(model_name)\n",
    "        for file_name in os.listdir(QA_folder_path):\n",
    "            with open(os.path.join(QA_folder_path, file_name), encoding='utf-8') as f:\n",
    "                sentences = f.read().split('\\n')\n",
    "                documents['Q'][file_name] = sentences\n",
    "                embedded_documents['Q'][file_name] = model.encode(sentences)\n",
    "        \n",
    "        for file_name in os.listdir(passages_folder_path):\n",
    "            with open(os.path.join(passages_folder_path, file_name), encoding='utf-8') as f:\n",
    "                sentences = f.read().split('\\n')\n",
    "                documents['p'][file_name] = sentences\n",
    "                embedded_documents['p'][file_name] = model.encode(sentences)\n",
    "\n",
    "        self.model = model\n",
    "        self.documents = documents\n",
    "        self.embedded_documents = embedded_documents\n",
    "        self.answers = None\n",
    "        #lens = np.array(sorted(list(map(len,reduce(lambda y,z: y+z, map(lambda x: self.documents[x], self.documents.keys())))), key=lambda t: -t))\n",
    "        #self.k = 2*(np.where(np.cumsum(lens)>=8000)[0][0]-1)\n",
    "\n",
    "    def cosine_similarity(self, a, b):\n",
    "        return a.dot(b)/(np.linalg.norm(a)*(np.linalg.norm(b)))\n",
    "\n",
    "    def retrieve_passages(self, question, domain, k=10):\n",
    "        Q = self.model.encode(question)\n",
    "        results = []\n",
    "        for base in domain:\n",
    "            for key in self.documents[base]:\n",
    "                for passage, K in zip(self.documents[base][key], self.embedded_documents[base][key]):\n",
    "                    results.append({'base':base, 'file':key,'name': passage, 'score':self.cosine_similarity(K,Q)})\n",
    "        return list(sorted(results, key=lambda x: -x['score']))[:k]\n",
    "\n",
    "    def populate_answers(self, folder_path):\n",
    "        answers = {}\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            with open(os.path.join(folder_path, file_name), encoding='utf-8') as f:\n",
    "                sentences = f.read().split('\\n')\n",
    "                for sentence in sentences:\n",
    "                    Q, A = sentence.split(' A. ')\n",
    "                    answers[Q] = A\n",
    "        self.answers = answers\n",
    "\n",
    "    def answer(self, question, db_path = 'data/QA/', domain=['Q','p']):\n",
    "        if self.answers is None:\n",
    "            self.populate_answers(db_path)\n",
    "        results = self.retrieve_passages(question, domain)\n",
    "        if results[0]['base'] == 'Q':\n",
    "            question = results[0]['name']\n",
    "            answer = self.answers[question]\n",
    "        else:\n",
    "            answer = self.generate_answer(question, results)\n",
    "        return answer, question\n",
    "\n",
    "    def generate_answer(self, question, results):\n",
    "        \n",
    "\n",
    "\n",
    "sd = SemanticDocument(QA_folder_path='data/Q/', passages_folder_path = 'data/passages/')#, model_name='dlicari/distil-ita-legal-bert')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q. Quanti giorni in modalità agile posso lavorare mensilmente?\n",
      "Puoi lavorare in agile il numero di giornate che hai chiesto nell'adesione, il numero massimo è 12 giorni.\n"
     ]
    }
   ],
   "source": [
    "question = \"Quanti giorni di smartworking posso fare?\"\n",
    "answer, question = sd.answer(question, domain=['Q'])\n",
    "print(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q. Posso lavorare in modalità agile da un Paese estero?\n",
      "sì è possibile, compatibilmente con la necessità di lavorare in presenza in alcune giornate.\n"
     ]
    }
   ],
   "source": [
    "question = \"Posso lavorare dalla Francia?\"\n",
    "answer, question = sd.answer(question)\n",
    "print(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q. Il mio responsabile mi può chiedere di fare una cosa alle 18?\n",
      "sì, può chiedertelo fino alle 19 ma tu non sei obbligato a farla se la tua giornata di lavoro è terminata.\n"
     ]
    }
   ],
   "source": [
    "question = \"Posso ammazzare il mio capo?\"\n",
    "answer, question = sd.answer(question)\n",
    "print(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q. Posso lavorare in modalità agile prima o dopo una giornata di ferie?\n",
      "Assolutamente sì.\n"
     ]
    }
   ],
   "source": [
    "question = \"Posso drogarmi durante l'orario lavorativo?\"\n",
    "answer, question = sd.answer(question)\n",
    "print(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Tuple, Union\n",
    "import openai\n",
    "openai.api_key = \"sk-W2v63UWK3U2J1CzRVFoAVhwIZkQd7mS4fqfrvd9E\"\n",
    "\n",
    "@dataclass\n",
    "class RequestConfig:\n",
    "    response_length: int = 500\n",
    "    temperature: float = 0\n",
    "    top_P: int = 1\n",
    "    frequency_penalty: float = 0\n",
    "    presence_penalty: float = 0.35\n",
    "    best_of: int = 1\n",
    "    stop_seqs = ['###']\n",
    "    logprobs: bool = False\n",
    "    model: str = \"text-davinci-003\"\n",
    "\n",
    "\n",
    "question = \"Posso lavorare dalla Siberia\"\n",
    "results = sd.retrieve_passages(question)\n",
    "passages = '\\n'.join(list(map(lambda x: x['name'], results)))\n",
    "prompt = f\"\"\"{passages}, Rispondi a questa domanda: \"{question}\" \"\"\"\n",
    "response = openai.Completion.create(prompt=prompt, model=RequestConfig.model, max_tokens=RequestConfig.response_length, temperature=RequestConfig.temperature, top_p=RequestConfig.top_P, frequency_penalty=RequestConfig.frequency_penalty, presence_penalty=RequestConfig.presence_penalty, best_of=RequestConfig.best_of)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "daf0f1fa32d3f21c84a957dbcd357f8c833f52e9c9d64ef79e8a7a7e419257b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
